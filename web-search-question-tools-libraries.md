# Ferramentas para Perguntas e Busca Web

* **Decomposição de perguntas**: Geralmente é feito usando modelos de linguagem (por exemplo, LLMs) ou bibliotecas de NLP. Não há biblioteca Node.js especializada de “decomposição” pronta, mas você pode usar APIs de IA (p. ex. OpenAI GPT) para dividir consultas complexas em subperguntas antes de buscar resposta. Em Node.js, pode-se chamar o SDK oficial da OpenAI (`openai` via npm) para gerar essa decomposição ou reformulação inteligente. Outras bibliotecas de NLP para Node (como `compromise`, `natural`, ou `spaCy` via serviços externos) também podem ajudar na análise de linguagem natural.
* **Busca web automatizada**: Para obter resultados de pesquisa geral, existem APIs pagas e gratuitas. Por exemplo, o *SerpAPI* é um serviço pago com biblioteca Node que “scrape” resultados do Google, Bing, etc., retornando JSON prontos. A API de Busca Web do Bing (Azure) também pode ser chamada via REST em Node.js (exige **subscription key** do Azure). Alternativamente, bibliotecas como `axios` podem ser usadas para acessar *mecanismos de busca customizados* (por exemplo, Google Custom Search, embora limitado) ou sites de busca acadêmica via pesquisa de HTML estático.
* **Coleta de dados estruturados/não estruturados**: Para páginas HTML públicas, o emparelhamento `Axios + Cheerio` é comum: o `axios` faz requisição HTTP e `cheerio` parseia o HTML como um DOM (jQuery-like). Em páginas dinâmicas, automação com navegador é necessária (ver seção de *crawling* abaixo). Para dados estruturados, APIs específicas (ver seção de artigos científicos) ou serviços de extração (como Diffbot) podem ser usados.
* **CAPTCHAs e intervenção manual**: Uma abordagem é usar navegadores “de cabeça erguida” (modo visível) e pausar o script quando aparecer um CAPTCHA, permitindo que o usuário resolva manualmente. Em Puppeteer/Playwright basta iniciar com `headless: false` e monitorar a presença de elementos de CAPTCHA; então, esperar intervenção do usuário antes de continuar. Em geral recomenda-se também rotacionar IPs (proxies residenciais) e modificar *user-agent* para evitar CAPTCHAs frequentes. Soluções pagas como 2Captcha/anti-captcha existem, mas aqui o foco é permitir **resolver manualmente** (scripts podem exibir uma mensagem e esperar input do usuário). Como observa-se em uma discussão de StackOverflow, “você precisa esperar o CAPTCHA aparecer em outro navegador e resolvê-lo lá” (terceirizando ou manualmente).

## Integração de APIs de IA Externa

* **OpenAI (GPT)**: A OpenAI oferece modelos de linguagem (GPT-3.5/4, embeddings, etc.) acessíveis via API. O pacote oficial `openai` no npm fornece acesso fácil aos endpoints de *completions*, *chat* ou *embeddings*. Por exemplo, para refinamento de pergunta ou sumarização, chama-se `client.chat.completions.create` em Node.js. É necessário obter uma chave de API da OpenAI e respeitar limites de uso (por token e por minuto).
* **SerpAPI**: Serviço pago especializado em buscas na web. Possui biblioteca Node (`serpapi`) com comandos como `getJson({ engine: "google", api_key: KEY, q: "consulta" })`. Retorna resultados do Google, Bing, Yandex, etc., já parseados em JSON. Útil para evitar lidar com anti-scraping diretamente, mas cobra por requisição.
* **Diffbot**: API paga para extração de dados estruturados de páginas web. Oferece endpoints como “Article API” ou “Analyze API” para extrair título, autor, texto, etc., de qualquer URL. Há wrappers Node (ex: `diffbot-api-node` no GitHub). Exige token de API e costuma cobrar por “crawls” ou transações.
* **Bing Web Search API (Microsoft Cognitive Services)**: API REST da Microsoft para pesquisa na web. Exige **chave de assinatura Azure** e permite buscas genéricas, retornando links, snippets e imagens. Pode ser acessada em Node usando `https` ou bibliotecas HTTP. Tem limites gratuitos baixos (por mês) e planos pagos maiores.
* **Outras estratégias**: Dependendo do caso, pode-se usar também serviços de NLP/IA externos para decomposição de consulta (ex: APIs de linguagem do Google, modelos Hugging Face via Inference API), ou bases de conhecimento estruturadas (Wikidata APIs, etc.). Mas OpenAI, SerpAPI, Diffbot e Bing cobrem os cenários principais.

### Comparativo rápido de APIs de IA (Node.js)

| Serviço/API         | Integração Node.js                       | Autenticação          | Uso/Tamanho de resposta             | Notas principais                                                  |
| ------------------- | ---------------------------------------- | --------------------- | ----------------------------------- | ----------------------------------------------------------------- |
| **OpenAI (GPT)**    | `npm install openai` + SDK oficial       | API Key (obrigatório) | Textos, embeddings, etc.            | Modelos avançados de LLM; limites por token; pago.                |
| **SerpAPI**         | `npm install serpapi` + `getJson()`      | API Key (pago)        | Resultados de busca (JSON)          | Suporta Google/Bing/etc; facilita scraping de SERP.               |
| **Diffbot**         | Via wrapper (`diffbot-api-node`) ou REST | Token (pago)          | JSON estruturado (artigos, páginas) | Extração estruturada de conteúdos web; uso por análise.           |
| **Bing Web Search** | HTTP GET ou SDK Azure Cognitive          | Chave Azure (pago)    | Resultados de busca (JSON)          | Retorna web, imagens, vídeos; integrado ao ecossistema Microsoft. |

Cada uma dessas APIs pode ser chamada diretamente de Node.js (via `axios`, `fetch`, ou SDKs próprios) e usada em fluxos assíncronos ou encadeados. Por exemplo, pode-se usar OpenAI para processar entrada do usuário, depois chamar SerpAPI para buscas, ou usar Bing API diretamente para pesquisa web.

## Bibliotecas de Crawling/Scraping em Node.js

* **Axios + Cheerio (ou Got, Superagent, etc.)**: `axios` é um cliente HTTP simples que busca conteúdo HTML; `cheerio` permite parsear HTML como um DOM (estilo jQuery). Essa combinação é **rápida e leve** para páginas estáticas. Permite customizar *headers*, *cookies* e outros parâmetros de requisição, ajudando a simular browsers reais. A desvantagem é que **JavaScript dinâmico não é executado**: sites SPA ou com conteúdo carregado via JS não funcionarão sem renderização. Também fica sujeita a bloqueios anti-bot se o site detectar padrões suspeitos.
* **Puppeteer (modo visível/headful)**: Biblioteca Node (do time Chrome) que controla o Chrome/Chromium via DevTools. Pode rodar em headless (padrão) ou *visível* (`headless: false`) para permitir interação manual. Excelente para páginas dinâmicas (SPAs, sites pesados em JS) e permite tirar screenshots/PDFs. Desvantagens: mais pesada (executa navegador completo) e sujeita a detecção anti-scraping (sem ferramentas extras); muitas vezes precisa de proxies e de timeout alto.
* **Playwright**: Semelhante ao Puppeteer, mas suporta múltiplos navegadores (Chrome, Firefox, WebKit). Desenvolvido pela Microsoft, possui recursos avançados como *auto-waiting* (pausa automática até elementos carregarem) e gravador de sessões. Também pode ser executado em modo *visível* para intervenção humana. É robusto para testes e scraping de sites complexos. Porém, por ser mais novo, ainda está em evolução e também requer gerenciar bloqueios anti-bot.
* **Selenium (WebDriver)**: Ferramenta tradicional para automação (usado também em Java/Python). Suporta muitos navegadores e linguagens (há um *WebDriver* para Node). É estável, mas mais verboso de usar em Node.js. Normalmente roda em modo visível por padrão, mas pode trabalhar headless. É útil se já existir infraestrutura Selenium (Grids). No entanto, é pesado e pode ser detectado como automação.
* **Outros**: Bibliotecas como **SimpleCrawler**, **Crawlee/Apify** ou **jsdom** existem, mas não foram especificadas na pergunta. Em geral, cabe avaliar caso a caso. Por exemplo, **ZenRows** é um serviço (API) que combina proxies e anti-CAPTCHA (pago), substituindo a necessidade de lidar com bloqueios manualmente.
* **Anti-bloqueios/CAPTCHAs**: Além do modo visível, algumas bibliotecas/plugins ajudam a contornar CAPTCHAs de forma semiautomática (ex: `puppeteer-extra-plugin-recaptcha` integrando 2Captcha). Porém, como a proposta aqui é intervenção manual, recomenda-se rodar o navegador no modo GUI e, ao detectar bloqueio, exibir instrução para o usuário resolver (ou usar proxy). Um estudo sugeriu combinar waits, proxies rotativos e mudanças de user-agent; e quando aparecer CAPTCHA, “resolva manualmente em outro navegador e continue”.

| Biblioteca/Serviço     | Características principais               | Vantagens                                                               | Limitações                                                |
| ---------------------- | ---------------------------------------- | ----------------------------------------------------------------------- | --------------------------------------------------------- |
| **Axios + Cheerio**    | Requisição HTTP + parsing HTML estático  | Muito rápido para HTML simples; leve; fácil controle de headers/cookies | Não executa JS; bloqueios fáceis em sites dinâmicos       |
| **Puppeteer**          | Automação de Chrome/Chromium             | Roda JavaScript complexo; screenshots; headful/headless                 | Pesado; detectável; consumo alto de recursos              |
| **Playwright**         | Automação multi-browser                  | Suporta Chrome, Firefox, WebKit; auto-waiting                           | Semelhante ao Puppeteer (pesado); ainda em crescimento    |
| **Selenium WebDriver** | Automação cross-browser (via WebDriver)  | Amplamente usado; suporta muitas linguagens                             | Mais verboso; dificuldade maior em Node; pesado           |
| **ZenRows (serviço)**  | API com proxies rotativos e anti-CAPTCHA | Bypass automático de CAPTCHAs e WAFs; simples de usar via requisição    | Pago; limita requisições diárias; menos controle granular |
| **Superagent/Got**     | Clientes HTTP flexíveis                  | Simples como Axios; vários plugins                                      | Igual Axios/Cheerio (não executa JS)                      |

## Busca em Artigos Científicos

Para fontes acadêmicas, há APIs públicas especializadas. As principais incluem:

* **Semantic Scholar**: Plataforma de pesquisa acadêmica da Allen Institute. Oferece o *Academic Graph API* (REST). Suporta busca por palavras-chave, título, DOI, autor, etc. Também permite filtrar resultados, por exemplo, por intervalo de anos ou campo de estudo (ver parâmetros `year` e `fieldsOfStudy`). A API é gratuita (sem necessidade de chave para uso básico) com limite de \~1000 requisições por segundo compartilhadas. Há limites adicionais em períodos de uso intenso e taxa inicial baixa quando se usa chave (1 RPS inicial, depois ajustável).
* **arXiv**: Repositório de pré-publicações. Dispõe de API gratuita (baseada em Atom/RSS). Usa o parâmetro `search_query` para busca (ex: `au:Nome+AND+ti:Termo`). Permite filtros por categorias (p. ex. cs.LG), autores, título, etc. Oferece filtro de data via `submittedDate` (formato `[YYYYMMDDHHMM+TO+YYYYMMDDHHMM]`). Retorna os metadados do artigo (título, autores, resumo, DOI, etc.) em formato XML. Não exige autenticação nem chave, mas recomenda-se modular as consultas para não sobrecarregar o serviço.
* **CrossRef**: Registro amplo de metadados de publicações (DOIs). A REST API pública permite buscar artigos por autores, título ou outros termos usando parâmetros como `query.author`, `query.bibliographic`. Além disso, há filtros específicos via `filter=`, como intervalo de datas de publicação (`from-pub-date`, `until-pub-date`), prefixo de DOI, ISSN de periódico, existência de texto completo, etc.. É gratuita e pública (não requer chave), mas tem limites de taxa razoáveis (\~50 req/s por IP; exceder retorna 429 com “retry-after” curto).
* **PubMed/NCBI (Entrez)**: Base da NLM. Fornece o *E-Utilities* (e.g. ESearch/Efetch) para buscar artigos no PubMed/PubMed Central. Aceita termos de busca como “Smith JA\[AU] 2020\[DP]” (autor e ano) e outros campos. Por padrão sem chave, a taxa é limitada a \~3 requests/segundo para todos os serviços NCBI; com uma API key gratuita do NCBI esse limite pode subir para \~10 requests/segundo. Resultados incluem IDs PMC/PubMed; deve-se usar EFetch/E Summary para obter detalhes (título, autores, resumo, etc.).
* **Europe PMC**: Base de artigos de ciências da vida e biomédicas. Sua API RESTful permite buscas livres e filtros (p. ex. `PUB_YEAR:2023`, `AUTHOR:"Nome Sobrenome"`, `OPEN_ACCESS:Y`) nas metadados. É gratuita e não exige autenticação, mas possui limites de chamada (cerca de 1 req/s por IP). Retorna JSON/XML com metadados e, quando disponível, links para PDF ou DOI.
* **Scopus (Elsevier)**: API comercial (Elsevier Developer Portal) que oferece busca federada em base Scopus. Requer **API Key** da Elsevier (assinatura paga). Suporta buscas por autor, afiliação, DOI, ISSN, palavra-chave, ano, etc. em múltiplas fontes (abstracts, citações, métricas). Limite de uso depende do plano (geralmente alguns milhares de queries por mês).
* **IEEE Xplore**: API de metadados da biblioteca IEEE. Exige cadastro e chave de API (licença da IEEE). Suporta parâmetros de busca como `author`, `doi`, `publication_year`, `index_terms`, `publication_title`, entre outros. Pode filtrar por conferência, journal, palavra-chave, etc. A resposta inclui títulos, autores, resumo, DOI, etc. Uso sujeito às cotas do IEEE (muitos serviços acadêmicos recebem acesso institucional).

| API/Coleção           | Autenticação                         | Filtros principais                                                                                         | Acesso/Limites                                                              |
| --------------------- | ------------------------------------ | ---------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------- |
| **Semantic Scholar**  | Chave opcional (recomendada)         | Consulta livre (title/abstract), filtros de ano e área                                                     | Grátis; \~1000 req/s (sem chave); 1 req/s inicial c/ chave                  |
| **arXiv**             | Não (API pública)                    | `search_query` (au, ti, cat, abs, etc.); `submittedDate`                                                   | Grátis; sem limite estrito, mas paginar (max \~2000 resultados por query).  |
| **CrossRef**          | Não (público, usa *mailto* na query) | `query.author`, `query.bibliographic`; filtros: `from-pub-date`, `until-pub-date`, prefixo DOI, ISSN, etc. | Grátis; \~50 req/s por IP (restringe a 10s bloqueio se ultrapassar).        |
| **PubMed (NCBI)**     | Não (ou chave NCBI opcional)         | Termos qualificados (\[AU] autor, \[TI] título, \[DP] ano, etc.); filtros ESearch (data).                  | Grátis; \~3 req/s sem chave (até \~10 rps c/ chave). Retorna IDs e resumos. |
| **Europe PMC**        | Não (API aberta)                     | Filtros de ano (`PUB_YEAR:YYYY`), autor (`AUTH:"Nome Sobrenome"`), acesso aberto, etc.                     | Grátis; \~1 req/s (por boa conduta). Retorna metadados e links de OA.       |
| **Scopus (Elsevier)** | API Key Necessária (pago)            | Busca avançada por autor, DOI, afiliação, ano, etc.; metadados e citações.                                 | Pago (assinatura); limites variam conforme plano (geralmente baixas cota).  |
| **IEEE Xplore**       | API Key (pago/academia)              | Parâmetros: `author`, `doi`, `publication_year`, `publication_title`, `index_terms`, etc.                  | Pago (requere licença); limites segundo o contrato do usuário.              |

Cada API acima pode ser acessada via HTTP (por exemplo, usando `axios` ou `fetch` em Node), muitas vezes com parâmetros na URL. Por exemplo, Semantic Scholar e Europe PMC retornam JSON nativo; arXiv retorna Atom/XML; CrossRef e PubMed/E-utilities também retornam JSON ou XML padronizados. É importante ler a documentação de cada serviço para construir consultas corretas e respeitar os limites de taxa (usar caching ou indexação local se precisar de várias consultas).

**Fontes**: Documentações oficiais das APIs e guias técnicos foram consultados para os detalhes acima, garantindo que as ferramentas e filtros listados estejam corretos e atualizados.
