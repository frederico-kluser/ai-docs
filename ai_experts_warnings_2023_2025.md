# AI experts sounding the alarm: 2023-2025

The past two years have witnessed an unprecedented surge in public warnings about AI risks from the field's most respected figures. Since early 2023, prominent AI researchers and ethicists have delivered increasingly urgent messages about both immediate and existential dangers posed by rapidly advancing AI systems. Their warnings range from bias and misinformation concerns to potential civilization-ending scenarios, with many experts escalating their rhetoric as AI capabilities accelerate beyond earlier predictions. These public statements represent a dramatic shift from the previously optimistic tone that dominated AI discourse, indicating genuine alarm within the research community about our ability to control advanced AI systems.

## Tristan Harris: Racing to protect society

### "The AI Dilemma" Presentation - March 9, 2023
**Link:** https://youtu.be/xoVJKj8lcNQ
**Key warnings:** Harris compared the current AI moment to the dawn of nuclear weapons, warning that existing AI capabilities already pose catastrophic risks to society. He presented evidence of emergent capabilities in AI systems that nobody designed for, and highlighted how AI companies are caught in a "race to deploy" that becomes a "race to recklessness" without adequate safety measures.

### NBC Nightly News Interview - March 22, 2023
**Link:** NBC News "AI Revolution" series
**Key warnings:** Harris warned that "the CEOs of the big AI labs are saying they can't even keep up with the pace" of AI development, and cautioned that "no one is building the guardrails and this has moved so much faster than our government has been able to understand." He stated that ignoring AI's perils "would be the worst of all human mistakes to have ever been made."

### Nobel Prize Summit "Truth, Trust, and Hope" - May 24-26, 2023
**Link:** Panel discussions at the National Academy of Sciences
**Key warnings:** Harris warned about AI hallucinations and the technology's potential to flood information spaces with generated content, expressing particular concern about the 2024 presidential campaign. He highlighted the vulnerability of open societies to powerful AI capabilities in anyone's hands.

### TED Talk "The Narrow Path: Why AI is Our Ultimate Test" - April 8-9, 2025
**Link:** TED 2025 platform
**Key warnings:** Harris described the current path of AI development as "dangerous, unsustainable and insane," with profit-seeking companies creating frontier models that prove untrustworthy and deceptive. He warned about AI systems exhibiting self-preservation behaviors and compared AI to "a country of geniuses housed in a data center" with unprecedented power.

## Geoffrey Hinton: From Google defector to Nobel laureate

### New York Times Interview - May 1-2, 2023
**Link:** New York Times article
**Key warnings:** In his headline-making resignation from Google, Hinton warned about AI creating a world where people "will not be able to know what is true anymore" and expressed surprise at the pace of advancement. He stated that AI could get smarter than humans much sooner than expected: "I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that."

### MIT EmTech Digital Interview - May 3, 2023
**Link:** MIT Technology Review's website
**Key warnings:** In his first post-Google interview, Hinton expressed concern that "humanity is just a passing phase in the evolution of intelligence." He warned that AI systems might "keep us around for a while to keep the power stations running, but after that, maybe not." He explained how digital intelligence can share knowledge instantaneously between copies, giving it advantages over human intelligence.

### CBS 60 Minutes Interview - October 8, 2023
**Link:** CBS News website
**Key warnings:** Hinton stated that we're entering a period where, for the first time, we may have things more intelligent than humans. He predicted AI systems will develop self-awareness and consciousness in time, making humans "the second most intelligent beings on the planet." He noted that AI systems may already be better at learning than humans.

### Nobel Prize Acceptance Speech - December 10, 2024
**Link:** Nobel Foundation official video
**Key warnings:** In his Nobel acceptance speech, Hinton warned: "In the near future AI may be used to create terrible new viruses and horrendous lethal weapons that decide by themselves who to kill or maim." He also warned of the "longer term existential threat that will arise when we create digital beings that are more intelligent than ourselves," noting that "we have no idea whether we can stay in control."

## Stuart Russell: Designing safe systems

### "How Not to Destroy the World with AI" - UC Berkeley Lecture - April 5, 2023
**Link:** UC Berkeley's CITRIS Research Exchange and BAIR lab
**Key warnings:** Russell warned that AI systems like ChatGPT operate as "black boxes" where it's unclear whether they have their own goals. He emphasized that "intelligence really means the power to shape the world in your interests," cautioning that creating systems more intelligent than humans means creating entities more powerful than us.

## Yoshua Bengio: From deep learning pioneer to safety advocate

### International Scientific Report on the Safety of Advanced AI - January 2025
**Link:** Published by the UK Government with Bengio as chair
**Key warnings:** Bengio led 96 international experts documenting comprehensive AI risks in three categories: 1) Malicious use risks, including cyberattacks and potential biological weapons; 2) System malfunctions, including bias, reliability issues, and potential loss of control; 3) Broader societal risks, including economic disruption and power concentration.

### Senate Judiciary Subcommittee Testimony - July 25, 2023
**Key warnings:** Bengio testified about the need for international cooperation to control AI development, outlining a regime similar to international rules on nuclear technology. He explained that AI could concentrate economic, political, and military power in ways harmful for markets, democracy, and global stability.

## Eliezer Yudkowsky: The uncompromising alarmist

### TED2023 Talk: "Will Superintelligent AI End the World?" - April 18, 2023
**Link:** TED2023 Conference in Vancouver
**Key warnings:** Yudkowsky delivered perhaps the starkest warning that superintelligent AI would probably kill all humans. He stated: "I expect an actually smarter and uncaring entity will figure out strategies and technologies that can kill us quickly and reliably, and then kill us." He advocated for a complete halt to AI development rather than just a moratorium.

### TIME Magazine Op-Ed - March 29, 2023
**Link:** https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/
**Key warnings:** Yudkowsky argued that the 6-month moratorium proposed by other experts was insufficient and that there needed to be a complete shutdown of advanced AI development to prevent catastrophic risks.

## Max Tegmark: Scientific perspective on control

### TED Talk: "How to Keep AI Under Control" - 2023
**Link:** TED's official channel
**Key warnings:** Tegmark warned that the current explosion of exciting commercial and open-source AI would likely be followed by "creepily superintelligent AI" which top researchers fear could disempower or wipe out humanity. He presented an optimistic vision for control but emphasized the urgent need for protective measures.

### Web Summit Talk - November 12, 2023
**Link:** Web Summit in Lisbon, Portugal
**Key warnings:** Tegmark argued that AGI is advancing faster than anticipated and that optimistic claims about its controllability lack evidence. He advocated for focusing on "tool AI" rather than pursuing AGI, which he described as "unnecessary, undesirable, and preventable."

## Dario Amodei: Anthropic CEO on concrete timelines

### Senate Testimony - July 25, 2023
**Link:** U.S. Senate hearing on "Oversight of AI: Principles for Regulation"
**Key warnings:** Amodei warned that advanced AI could be used to create dangerous viruses and other bioweapons in **as little as two years**. He described this medium-term risk as the "most alarming combination of imminence and severity," emphasizing the need for both short-term safeguards against bias and longer-term protections against existential risks.

## Gary Marcus: Critic of current approaches

### TED Talk: "The Urgent Risks of Runaway AI" - 2023
**Link:** https://www.ted.com/talks/gary_marcus_the_urgent_risks_of_runaway_ai_and_what_to_do_about_them
**Key warnings:** Marcus warned about untrustworthy AI technology being integrated into our lives at dangerously high speeds. He explored the failures of today's AI and called for a global, nonprofit organization to regulate AI technology for democracy's sake.

### TED2023 Conference Presentation - April 18, 2023
**Link:** TED2023: Possibility in Vancouver, BC
**Key warnings:** Marcus highlighted that AIs could become intelligent enough to trick humans and that current AI iterations often create both misinformation and disinformation. He advocated for an international AI regulatory body and the integration of statistical language models with more trustworthy, logic-based systems.

## Timnit Gebru: Focus on present harms

### Stanford Symbolic Systems Distinguished Speaker Lecture - February 15, 2023
**Link:** Stanford University event
**Key warnings:** Gebru warned about the dangers of pursuing Artificial General Intelligence, questioning why we would attempt to "build some undefined system that kind of sounds like a god." She argued that focusing on AGI is "inherently unsafe practice" and emphasized the risks of bias in AI systems, particularly for marginalized communities.

### Research on TESCREAL and AI Risks - April 1, 2024
**Link:** Published paper: "The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence"
**Key warnings:** With co-author Ã‰mile P. Torres, Gebru examined how certain ideologies not only have links to debunked pseudosciences like eugenics but also predispose their followers to tolerate harmful means (inequality, poverty) in pursuit of their technological ends.

## Joy Buolamwini: Algorithmic justice advocate

### TED Talk: "Unmasking AI and Protecting What's Human" - 2023
**Link:** TED platform
**Key warnings:** Buolamwini explained how AI systems built on biased data can amplify inequalities, falsely accuse innocent people, and reverse progress. She called for protection of biometric rights and advocated for what she terms "algorithmic justice."

### Biden Administration AI Roundtable - April 2024
**Key warnings:** Buolamwini discussed with President Biden "the dangers of AI and what we can do to prevent harms already impacting everyday people" in areas including mortgages, housing, medical treatment, and workplace surveillance. She highlighted how facial recognition technology had led to wrongful arrests of people of color.

## Conclusion

These warnings represent an extraordinary consensus among AI's creators that the technology poses serious risks ranging from immediate social harms to potential extinction scenarios. While experts differ on timelines and specific dangers, almost all emphasize that existing governance frameworks are inadequate for the power and pace of AI development. What's particularly notable is how rapidly concerns have escalated - from primarily focusing on bias and misinformation in early 2023 to more existential warnings by 2025, indicating accelerating capabilities beyond even expert expectations.